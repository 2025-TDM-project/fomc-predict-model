!pip install selenium
import pandas as pd
from selenium import webdriver
from selenium.webdriver.common.by import By
from selenium.webdriver.support.ui import WebDriverWait
from selenium.webdriver.support import expected_conditions as EC
from selenium.common.exceptions import TimeoutException
import time
import os
from google.colab import drive

# Google Drive ë§ˆìš´íŠ¸
drive.mount('/content/drive')

# ì„¤ì •
DRIVE_FOLDER = '/content/drive/MyDrive/scraping_data'  # Drive ì €ì¥ ê²½ë¡œ
CSV_FILE = os.path.join(DRIVE_FOLDER, 'bond_report.csv')
PROGRESS_FILE = os.path.join(DRIVE_FOLDER, 'progress.txt')  # ì§„í–‰ìƒí™© ê¸°ë¡
SAVE_INTERVAL = 50  # 50ê°œë§ˆë‹¤ ì €ì¥ (ìì£¼ ì €ì¥)
START_ID = 491773
END_ID = 450000
RESTART_INTERVAL = 500  # 500ê°œë§ˆë‹¤ ë“œë¼ì´ë²„ ì¬ì‹œì‘

# í´ë” ìƒì„±
os.makedirs(DRIVE_FOLDER, exist_ok=True)
print(f"ğŸ“ ì €ì¥ ê²½ë¡œ: {DRIVE_FOLDER}\n")

# ì§„í–‰ìƒí™© ë¶ˆëŸ¬ì˜¤ê¸°
if os.path.exists(PROGRESS_FILE):
    with open(PROGRESS_FILE, 'r') as f:
        last_processed_id = int(f.read().strip())
    start_from = last_processed_id  # ë§ˆì§€ë§‰ ì²˜ë¦¬í•œ IDë¶€í„° ì‹œì‘ (ì´ë¯¸ -1 ì²˜ë¦¬ë¨)
    print(f"âœ… ì§„í–‰ìƒí™© íŒŒì¼ ë°œê²¬! ID {start_from}ë¶€í„° ì´ì–´ì„œ ì‹œì‘í•©ë‹ˆë‹¤.")
else:
    start_from = START_ID
    print(f"âœ… ìƒˆë¡œ ì‹œì‘í•©ë‹ˆë‹¤. ID {start_from}ë¶€í„° ì‹œì‘.")

# ê¸°ì¡´ ë°ì´í„° ë¶ˆëŸ¬ì˜¤ê¸°
if os.path.exists(CSV_FILE):
    existing_df = pd.read_csv(CSV_FILE)
    collected_titles = existing_df['title'].tolist()
    collected_dates = existing_df['date'].tolist()
    collected_contents = existing_df['content'].tolist()
    collected_urls = existing_df['main_path'].tolist()
    print(f"âœ… ê¸°ì¡´ ë°ì´í„° {len(existing_df)}ê°œ ë¡œë“œ ì™„ë£Œ\n")
else:
    collected_titles = []
    collected_dates = []
    collected_contents = []
    collected_urls = []
    print("âœ… ìƒˆ ë°ì´í„° ìˆ˜ì§‘ ì‹œì‘\n")

def create_driver():
    options = webdriver.ChromeOptions()
    options.add_argument('headless')
    options.add_argument('--no-sandbox')
    options.add_argument('--disable-dev-shm-usage')
    options.add_argument('--disable-blink-features=AutomationControlled')
    options.add_argument('user-agent=Mozilla/5.0 (Windows NT 10.0; Win64; x64) AppleWebKit/537.36')
    options.add_argument('--disable-gpu')
    options.page_load_strategy = 'eager'
    return webdriver.Chrome(options=options)

def save_data(current_id):
    """ë°ì´í„°ì™€ ì§„í–‰ìƒí™© ì €ì¥"""
    df_temp = pd.DataFrame({
        'title': collected_titles,
        'date': collected_dates,
        'content': collected_contents,
        'main_path': collected_urls
    })
    df_temp.to_csv(CSV_FILE, index=False, encoding='utf-8-sig')

    # ì§„í–‰ìƒí™© ì €ì¥
    with open(PROGRESS_FILE, 'w') as f:
        f.write(str(current_id))

    print(f"ğŸ’¾ Drive ì €ì¥ ì™„ë£Œ: {len(df_temp)}ê°œ (í˜„ì¬ ID: {current_id})")

driver = create_driver()
wait = WebDriverWait(driver, 15)
count = 0
success_count = 0

print("ğŸš€ ìŠ¤í¬ë˜í•‘ ì‹œì‘...\n")

# ë°ì´í„° ìˆ˜ì§‘
for i in range(start_from, END_ID, -1):
    url = f'https://tradingeconomics.com/united-states/government-bond-yield/news/{i}'

    # ë“œë¼ì´ë²„ ì£¼ê¸°ì  ì¬ì‹œì‘
    if count > 0 and count % RESTART_INTERVAL == 0:
        print(f"\nğŸ”„ ë“œë¼ì´ë²„ ì¬ì‹œì‘ ì¤‘...")
        driver.quit()
        time.sleep(3)
        driver = create_driver()
        wait = WebDriverWait(driver, 15)

    retries = 3
    success = False

    for attempt in range(retries):
        title = None
        date = None
        content = None

        driver.get(url)
        time.sleep(1.5)

        title_element = wait.until(
            EC.presence_of_element_located((By.XPATH, "//h1[@class='news_title']"))
        )
        title = title_element.text.strip()

        date_element = driver.find_element(By.XPATH, "//div[@class='news_info']//span[1]")
        date = date_element.text.strip()

        content_elements = driver.find_elements(By.XPATH, "//div[@class='news_description']/p")
        if content_elements:
            content = "\n\n".join([e.text.strip() for e in content_elements if e.text.strip()])

        if title and date:
            collected_titles.append(title)
            collected_dates.append(date)
            collected_contents.append(content if content else "")
            collected_urls.append(url)
            success_count += 1
            success = True

            if success_count % 10 == 0:
                print(f"âœ… ID {i} ì™„ë£Œ (ì´ {success_count}ê°œ)")
            break

        elif attempt < retries - 1:
            time.sleep(2)

    if not success:
        print(f"âŒ ID {i} ìŠ¤í‚µ")

    count += 1

    # ì£¼ê¸°ì  ì €ì¥ (Driveì— ì €ì¥)
    if success_count > 0 and success_count % SAVE_INTERVAL == 0:
        save_data(i)

    # ì§„í–‰ìƒí™© í‘œì‹œ
    if count % 100 == 0:
        print(f"\nğŸ“Š ì§„í–‰: {count}íšŒ ì‹œë„, {success_count}ê°œ ìˆ˜ì§‘, í˜„ì¬ ID: {i}\n")

# ìµœì¢… ì €ì¥
driver.quit()
save_data(END_ID)

print("\n" + "="*60)
print("âœ… ìŠ¤í¬ë˜í•‘ ì™„ë£Œ!")
print("="*60)
print(f"ì´ ìˆ˜ì§‘: {len(collected_titles)}ê°œ")
print(f"ì €ì¥ ìœ„ì¹˜: {CSV_FILE}")
print(f"ì§„í–‰ ê¸°ë¡: {PROGRESS_FILE}")

# ìµœì¢… ê²°ê³¼
df_final = pd.read_csv(CSV_FILE)
print(f"\nìµœì¢… ë°ì´í„°í”„ë ˆì„: {len(df_final)}í–‰")
print(df_final.head())
