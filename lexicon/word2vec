from tqdm import tqdm
import pandas as pd
import numpy as np
from ast import literal_eval  # [ì¤‘ìš”] ë¬¸ìì—´ì„ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜í•˜ëŠ” ë„êµ¬
from gensim.models import Word2Vec
import logging
import os

# ---------------------------------------------------------
# 1. ë°ì´í„° ë¡œë“œ ë° ì „ì²˜ë¦¬
# ---------------------------------------------------------
# ê²½ë¡œ ì„¤ì • (ì‹¤ì œ ê²½ë¡œ í™•ì¸)
ngram_path = r'C:\TMD_Project\master_ngram_dictionary.csv'
df_path = r'C:\TMD_Project\df_master_TM_proj_lemma.csv'

print("ë°ì´í„° ë¡œë”© ì¤‘...")
ngram_df = pd.read_csv(ngram_path)
df = pd.read_csv(df_path)

# [ì¤‘ìš”] CSVì—ì„œ ë¶ˆëŸ¬ì˜¨ 'í…ìŠ¤íŠ¸ ë¦¬ìŠ¤íŠ¸' ì»¬ëŸ¼ì„ ì§„ì§œ ë¦¬ìŠ¤íŠ¸ë¡œ ë³€í™˜
# ë°ì´í„°ê°€ "['ë‹¨ì–´', 'ë‹¨ì–´']" í˜•íƒœì˜ ë¬¸ìì—´ë¡œ ë˜ì–´ìˆë‹¤ê³  ê°€ì •í•©ë‹ˆë‹¤.
print("ë°ì´í„° íƒ€ì… ë³€í™˜ ì¤‘ (String -> List)...")
try:
    # ë§Œì•½ ë°ì´í„°ê°€ ì´ë¯¸ ê³µë°±ìœ¼ë¡œ êµ¬ë¶„ëœ ë¬¸ìì—´("ê¸ˆë¦¬ ì¸ìƒ ë…¼ì˜")ì´ë¼ë©´ ì´ ë‹¨ê³„ëŠ” ê±´ë„ˆë›°ê±°ë‚˜ ì—ëŸ¬ê°€ ë‚  ìˆ˜ ìˆìŒ
    # ì•ˆì „í•˜ê²Œ ì²˜ë¦¬í•˜ê¸° ìœ„í•´ ìƒ˜í”Œ í™•ì¸ í›„ ì ìš©
    sample = df['cleaned_text_lemma'].iloc[0]
    if isinstance(sample, str) and sample.startswith('[') and sample.endswith(']'):
        df['cleaned_text_lemma'] = df['cleaned_text_lemma'].apply(literal_eval)
except Exception as e:
    print(f"âš ï¸ ë¦¬ìŠ¤íŠ¸ ë³€í™˜ ì¤‘ ì—ëŸ¬ ë°œìƒ (ë˜ëŠ” ì´ë¯¸ ë¦¬ìŠ¤íŠ¸ í˜•ì‹ì´ ì•„ë‹˜): {e}")
    # ì—ëŸ¬ê°€ ë‚˜ë©´ ê·¸ëƒ¥ ì§„í–‰ (ë°ì´í„°ê°€ ê³µë°± êµ¬ë¶„ í…ìŠ¤íŠ¸ì¼ ìˆ˜ë„ ìˆìœ¼ë¯€ë¡œ)

# ê²°ì¸¡ì¹˜ ì œê±°
df = df.dropna(subset=['cleaned_text_lemma'])

# ---------------------------------------------------------
# 2. ì¹˜í™˜ íŒ¨í„´ ìƒì„± (ê¸´ ë‹¨ì–´ ìš°ì„ )
# ---------------------------------------------------------
# ';' ì²˜ë¦¬ ë° ê¸¸ì´ ê³„ì‚°
ngram_df['ngram_pattern'] = ngram_df['ngram'].str.replace(';', ' ')
ngram_df['length'] = ngram_df['ngram_pattern'].apply(lambda x: len(str(x).split()))

# ì •ë ¬: ê¸¸ì´ ê¸´ ìˆœ -> ì ìˆ˜ ë†’ì€ ìˆœ
sorted_ngrams = ngram_df.sort_values(by=['length', 'score'], ascending=[False, False])

replacement_list = []
for idx, row in sorted_ngrams.iterrows():
    pattern = row['ngram_pattern']
    replacement = pattern.replace(" ", "_")
    replacement_list.append((pattern, replacement))

print(f"ì¹˜í™˜ íŒ¨í„´ ì¤€ë¹„ ì™„ë£Œ: {len(replacement_list)}ê°œ")


# ---------------------------------------------------------
# 3. ì¹˜í™˜ í•¨ìˆ˜ ì •ì˜
# ---------------------------------------------------------
def apply_ngram_replacement(token_input, replace_patterns):
    # 1. ì…ë ¥ê°’ì´ ë¦¬ìŠ¤íŠ¸ì¸ ê²½ìš° ê³µë°± ë¬¸ìì—´ë¡œ ë³€í™˜
    if isinstance(token_input, list):
        text = " ".join(token_input)
    elif isinstance(token_input, str):
        text = token_input
    else:
        return []  # NaNì´ë‚˜ ìˆ«ìì¸ ê²½ìš° ë¹ˆ ë¦¬ìŠ¤íŠ¸ ë°˜í™˜

    # 2. ì¹˜í™˜ ìˆ˜í–‰
    for pattern, replacement in replace_patterns:
        if pattern in text:
            text = text.replace(pattern, replacement)

    # 3. ê²°ê³¼ ë°˜í™˜ (ë‹¤ì‹œ ë¦¬ìŠ¤íŠ¸ë¡œ)
    return text.split()


# ---------------------------------------------------------
# 4. ì‹¤í–‰ (ì¹˜í™˜ ì ìš©)
# ---------------------------------------------------------
tqdm.pandas()
print("N-gram ì¹˜í™˜ ì‹œì‘... (ë°ì´í„° í¬ê¸°ì— ë”°ë¼ ì‹œê°„ì´ ì†Œìš”ë©ë‹ˆë‹¤)")

df['ngram_text_lemma'] = df['cleaned_text_lemma'].progress_apply(
    lambda x: apply_ngram_replacement(x, replacement_list)
)

# ê²°ê³¼ ìƒ˜í”Œ í™•ì¸
print("\n[ìƒ˜í”Œ í™•ì¸]")
print(f"ì›ë³¸: {df['cleaned_text_lemma'].iloc[0]}")
print(f"ì¹˜í™˜: {df['ngram_text_lemma'].iloc[0]}")

# ---------------------------------------------------------
# 5. ì €ì¥ (ì¤‘ê°„ ê²°ê³¼)
# ---------------------------------------------------------
df.to_pickle(r"C:\TMD_Project\corpus_with_ngrams.pkl")
print("ì¤‘ê°„ ë°ì´í„° ì €ì¥ ì™„ë£Œ (pickle)")

# ---------------------------------------------------------
# 6. Word2Vec í•™ìŠµ
# ---------------------------------------------------------
logging.basicConfig(format='%(asctime)s : %(levelname)s : %(message)s', level=logging.INFO)

sentences = df['ngram_text_lemma'].tolist()
print(f"Word2Vec í•™ìŠµ ì‹œì‘ (ë¬¸ì¥ ìˆ˜: {len(sentences):,})")

model = Word2Vec(
    sentences=sentences,
    vector_size=100,
    window=5,
    min_count=10,  # ë°ì´í„°ê°€ ì ìœ¼ë©´ 5ë¡œ ë‚®ì¶”ëŠ” ê²ƒë„ ê³ ë ¤
    workers=4,
    sg=1,  # Skip-gram (í•„ìˆ˜)
    epochs=10,
    seed=42
)

# ëª¨ë¸ ì €ì¥
model.save(r"C:\TMD_Project\ngram_col_word2vec.model")
print("âœ… ëª¨ë¸ í•™ìŠµ ë° ì €ì¥ ì™„ë£Œ!")


# ---------------------------------------------------------
# 7. ê²€ì¦
# ---------------------------------------------------------
def check_similarity(word):
    try:
        similar_words = model.wv.most_similar(word, topn=10)
        print(f"\nğŸ”¹ '{word}'ì™€ ê°€ì¥ ìœ ì‚¬í•œ í‘œí˜„ TOP 10:")
        for w, sim in similar_words:
            print(f"  - {w} ({sim:.4f})")
    except KeyError:
        print(f"\nâš ï¸ '{word}'ëŠ” ë‹¨ì–´ ì‚¬ì „ì— ì—†ìŠµë‹ˆë‹¤. (ë¹ˆë„ìˆ˜ ë¶€ì¡± ë“±)")


# í…ŒìŠ¤íŠ¸
check_similarity("rate_hike")         # ê¸ˆë¦¬ ì¸ìƒ
check_similarity("price_stability")   # ë¬¼ê°€ ì•ˆì •
check_similarity("monetary_policy")   # í†µí™” ì •ì±…

# 2. ì¼ë°˜ ì£¼ìš” ë‹¨ì–´ í™•ì¸ (Unigrams)
check_similarity("inflation")         # ì¸í”Œë ˆì´ì…˜
check_similarity("liquidity")         # ìœ ë™ì„±
check_similarity("recession")         # ê²½ê¸° ì¹¨ì²´
